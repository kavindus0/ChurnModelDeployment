{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Preparation and Preprocessing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from matplotlib import pyplot as plt\n",
                "from sklearn.pipeline import Pipeline\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Raw Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('data/raw/dataset.csv')\n",
                "print(\"Successfully loaded dataset. Shape: \", df.shape)\n",
                "print(\"Columns: \", df.columns.tolist())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Engineering and Preprocessing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1. Define Feature Categories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "remainder_features = ['NumOfProducts', 'HasCrCard', 'IsActiveMember']\n",
                "numerical_features = ['Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
                "nominal_features = ['Gender', 'Geography']\n",
                "ordinal_features = ['CreditScoreBins']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2. Create Preprocessing Pipelines"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numerical_transformer = Pipeline(\n",
                "    steps=[\n",
                "        ('imputer', SimpleImputer(strategy='median')),\n",
                "        ('scaler', StandardScaler())\n",
                "    ]\n",
                ")\n",
                "\n",
                "nominal_transformer = Pipeline(\n",
                "    steps=[\n",
                "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
                "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
                "    ]\n",
                ")\n",
                "\n",
                "ordinal_transformer = Pipeline(\n",
                "    steps=[\n",
                "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
                "        ('encoder', OrdinalEncoder())\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3. Combine Pipelines with ColumnTransformer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', numerical_transformer, numerical_features),\n",
                "        ('nom', nominal_transformer, nominal_features),\n",
                "        ('ord', ordinal_transformer, ordinal_features),\n",
                "    ],\n",
                "    remainder='drop'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4. Apply Transformations and Create Final DataFrame"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_cp = df.copy()\n",
                "transformed_data = preprocessor.fit_transform(df_cp)\n",
                "\n",
                "# Get feature names after one-hot encoding\n",
                "nominal_feature_name = preprocessor.named_transformers_['nom']['encoder'].get_feature_names_out(nominal_features)\n",
                "\n",
                "df_transformed = pd.DataFrame(\n",
                "    transformed_data,\n",
                "    columns=numerical_features + list(nominal_feature_name) + ordinal_features\n",
                ")\n",
                "\n",
                "df_remainder = df[remainder_features]\n",
                "\n",
                "df_final = pd.concat(\n",
                "    [df_transformed, df_remainder, df_cp.Exited],\n",
                "    axis=1\n",
                ")\n",
                "\n",
                "print(\"Final preprocessed DataFrame head:\")\n",
                "display(df_final.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.5. Save Preprocessed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_final.to_csv('data/processed/x_transformed.csv', index=False)\n",
                "print(\"Preprocessed data saved to 'data/processed/x_transformed.csv'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Handle Class Imbalance using SMOTE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First, we split the data into training and testing sets. Then, we apply SMOTE only to the training data to prevent data leakage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df_final.drop(columns=['Exited'])\n",
                "Y = df_final['Exited']\n",
                "\n",
                "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Original class distribution in training data:\")\n",
                "print(Y_train.value_counts())\n",
                "\n",
                "# Apply SMOTE\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_resampled, Y_train_resampled = smote.fit_resample(X_train, Y_train)\n",
                "\n",
                "print(\"\\nResampled class distribution in training data:\")\n",
                "print(pd.Series(Y_train_resampled).value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1. Visualize Class Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(18, 5))\n",
                "\n",
                "plt.subplot(1, 3, 1)\n",
                "Y_train.value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
                "plt.ylabel('Count')\n",
                "plt.xlabel('Class')\n",
                "plt.title('Class Distribution Before SMOTE')\n",
                "plt.xticks(rotation=0)\n",
                "\n",
                "plt.subplot(1, 3, 2)\n",
                "pd.Series(Y_train_resampled).value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
                "plt.ylabel('Count')\n",
                "plt.xlabel('Class')\n",
                "plt.title('Class Distribution After SMOTE')\n",
                "plt.xticks(rotation=0)\n",
                "\n",
                "plt.subplot(1, 3, 3)\n",
                "Y_test.value_counts().plot(kind='bar', color=['lightgreen', 'gold'])\n",
                "plt.ylabel('Count')\n",
                "plt.xlabel('Class')\n",
                "plt.title('Class Distribution in Test Set')\n",
                "plt.xticks(rotation=0)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Save Processed Data Artifacts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.savez('artifacts/X_train.npz', X_train_resampled)\n",
                "np.savez('artifacts/Y_train.npz', Y_train_resampled)\n",
                "np.savez('artifacts/X_test.npz', X_test.values)\n",
                "np.savez('artifacts/Y_test.npz', Y_test.values)\n",
                "\n",
                "print(\"Saved processed data artifacts to the 'artifacts/' directory.\")\n",
                "print(f\"X_train_resampled shape: {X_train_resampled.shape}\")\n",
                "print(f\"Y_train_resampled shape: {Y_train_resampled.shape}\")\n",
                "print(f\"X_test shape: {X_test.shape}\")\n",
                "print(f\"Y_test shape: {Y_test.shape}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}