{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation ‡∂ö‡∑í‡∂∫‡∂±‡∑ä‡∂±‡∑ö Machine Learning models ‡∑Ä‡∂Ω performance ‡∂ë‡∂ö ‡∂±‡∑í‡∑Ä‡∑ê‡∂ª‡∂Ø‡∑í‡∑Ä ‡∂∏‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂± ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∑Ä‡∑ö‡∂Ø‡∂∫‡∂ö‡∑í.\n",
    "\n",
    "## ‡∂∏‡∑ñ‡∂Ω‡∑í‡∂ö ‡∑É‡∂Ç‡∂ö‡∂Ω‡∑ä‡∂¥‡∂∫\n",
    "\n",
    "üéØ **‡∑É‡∂ª‡∂Ω ‡∂Ö‡∂ª‡∑ä‡∂Æ‡∂ö‡∂Æ‡∂±‡∂∫**: ‡∂î‡∂∂‡∑ö data set ‡∂ë‡∂ö K ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä ‡∑Ä‡∂Ω‡∂ß ‡∂∂‡∑ô‡∂Ø‡∂Ω‡∑è, ‡∂ë‡∂ö‡∑ä ‡∂ö‡∑ú‡∂ß‡∑É‡∂ö‡∑ä testing ‡∑É‡∂≥‡∑Ñ‡∑è‡∂≠‡∑ä, ‡∂â‡∂≠‡∑í‡∂ª‡∑í ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä training ‡∑É‡∂≥‡∑Ñ‡∑è‡∂≠‡∑ä ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏.\n",
    "\n",
    "## K-Fold Cross Validation ‡∑Ä‡∂Ω ‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª\n",
    "\n",
    "### 1. Data ‡∑Ä‡∑í‡∂∑‡∑è‡∂ú‡∂∫ (Data Splitting)\n",
    "- ‡∑É‡∂∏‡∑ä‡∂¥‡∑ñ‡∂ª‡∑ä‡∂´ dataset ‡∂ë‡∂ö **K ‡∑É‡∂∏‡∑è‡∂± ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä** ‡∑Ä‡∂Ω‡∂ß ‡∂∂‡∑ô‡∂Ø‡∂±‡∑ä‡∂±\n",
    "- ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä K = 5 ‡∑Ñ‡∑ù K = 10 ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑Ä‡∑è\n",
    "\n",
    "### 2. Training ‡∑É‡∑Ñ Testing\n",
    "- **K ‡∑Ä‡∂≠‡∑è‡∑Ä‡∂ö‡∑ä** model ‡∂ë‡∂ö train ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "- ‡∑É‡∑ë‡∂∏ ‡∑Ä‡∂≠‡∑è‡∑Ä‡∂ö‡∂∏ **‡∑Ä‡∑ô‡∂±‡∑É‡∑ä ‡∂ö‡∑ú‡∂ß‡∑É‡∂ö‡∑ä** testing ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "\n",
    "### 3. Performance ‡∂ú‡∂´‡∂±‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏\n",
    "- ‡∑É‡∑ë‡∂∏ fold ‡∂ë‡∂ö‡∂ö‡∂∏ accuracy ‡∂ë‡∂ö ‡∂ú‡∂´‡∂±‡∂∫ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "- **‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫ accuracy** ‡∂ë‡∂ö ‡∂ú‡∂´‡∂±‡∂∫ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "\n",
    "## ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´‡∂∫ - 5-Fold Cross Validation\n",
    "\n",
    "```\n",
    "Dataset: [A, B, C, D, E] (5 ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä)\n",
    "\n",
    "Fold 1: Train=[B,C,D,E], Test=[A]\n",
    "Fold 2: Train=[A,C,D,E], Test=[B]  \n",
    "Fold 3: Train=[A,B,D,E], Test=[C]\n",
    "Fold 4: Train=[A,B,C,E], Test=[D]\n",
    "Fold 5: Train=[A,B,C,D], Test=[E]\n",
    "```\n",
    "\n",
    "## ‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç ‡∑Ä‡∂ª‡∑ä‡∂ú\n",
    "\n",
    "### 1. Stratified K-Fold\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Class distribution ‡∂ë‡∂ö maintain ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=skfold)\n",
    "```\n",
    "\n",
    "### 2. Leave-One-Out (LOO)\n",
    "```python\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# K = n (‡∑É‡∑í‡∂∫‡∂Ω‡∑î‡∂∏ samples)\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(model, X, y, cv=loo)\n",
    "```\n",
    "\n",
    "## K-Fold CV ‡∑Ä‡∂Ω ‡∑Ä‡∑è‡∑É‡∑í\n",
    "\n",
    "‚úÖ **Overfitting ‡∂Ö‡∑Ä‡∂∏ ‡∂ö‡∂ª‡∂∫‡∑í**: ‡∑É‡∑í‡∂∫‡∂Ω‡∑î‡∂∏ data points testing ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∑Ä‡∑ö  \n",
    "‚úÖ **Reliable results**: ‡∑Ä‡∂©‡∑è ‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä‡∑É‡∂±‡∑ì‡∂∫ performance metrics  \n",
    "‚úÖ **Data efficiency**: ‡∑É‡∂∏‡∑ä‡∂¥‡∑ñ‡∂ª‡∑ä‡∂´ dataset ‡∂ë‡∂ö‡∂∏ training ‡∑É‡∑Ñ testing ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∑Ä‡∑ö  \n",
    "‚úÖ **Variance ‡∂Ö‡∑Ä‡∂∏ ‡∂ö‡∂ª‡∂∫‡∑í**: Multiple evaluations ‡∂±‡∑í‡∑É‡∑è stable results  \n",
    "\n",
    "## ‡∂Ö‡∑Ä‡∑è‡∑É‡∑í\n",
    "\n",
    "‚ùå **Computational cost**: K ‡∑Ä‡∂≠‡∑è‡∑Ä‡∂ö‡∑ä model train ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö  \n",
    "‚ùå **Time consuming**: ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω datasets ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂ö‡∑è‡∂Ω‡∂∫ ‡∂ú‡∂≠‡∑Ä‡∑ö  \n",
    "‚ùå **Memory usage**: Multiple models memory ‡∂ë‡∂ö‡∑ö store ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö  \n",
    "\n",
    "## Mnemonics (‡∂∏‡∂≠‡∂ö ‡∑É‡∂ß‡∑Ñ‡∂±‡∑ä)\n",
    "\n",
    "### \"KFOLD\" Mnemonic:\n",
    "- **K** - ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä ‡∂ö‡∂ª‡∂±‡∑ä‡∂± (Split into K parts)\n",
    "- **F** - ‡∑É‡∑ë‡∂∏ Fold ‡∂ë‡∂ö‡∂ö‡∂∏ (For each Fold)  \n",
    "- **O** - ‡∂ë‡∂ö‡∑ä ‡∂ö‡∑ú‡∂ß‡∑É‡∂ö‡∑ä Outside (One part Outside for testing)\n",
    "- **L** - ‡∂â‡∂≠‡∑í‡∂ª‡∑í ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä Learn (Rest Learn/Train)\n",
    "- **D** - ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂µ‡∂Ω Determine ‡∂ö‡∂ª‡∂±‡∑ä‡∂± (Determine results)\n",
    "\n",
    "### \"TRAIN-TEST\" Pattern:\n",
    "```\n",
    "üöÇ TRAIN ‚Üí üß™ TEST ‚Üí üìä SCORE\n",
    "   (4/5)     (1/5)      (Accuracy)\n",
    "```\n",
    "\n",
    "| ‚úÖ **‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±** | ‚ùå **‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂±‡∑ú‡∂ö‡∂ª‡∂±‡∑ä‡∂±** |\n",
    "|----------------------|-------------------------|\n",
    "| üìä Small to medium datasets ‡∑É‡∂≥‡∑Ñ‡∑è | üíæ Very large datasets (computational cost) |\n",
    "| üîÑ Model comparison ‡∑É‡∂≥‡∑Ñ‡∑è | ‚è∞ Time series data (temporal order important) |\n",
    "| ‚öôÔ∏è Hyperparameter tuning ‡∑É‡∂≥‡∑Ñ‡∑è | ‚öñÔ∏è Highly imbalanced datasets (without stratification) |\n",
    "| üìà Final model performance evaluate ‡∂ö‡∂ª‡∂±‡∑ä‡∂± | üöÄ Real-time applications (speed critical) |\n",
    "| üéØ Model selection ‡∑É‡∂≥‡∑Ñ‡∑è | üîí Privacy-sensitive data (multiple copies) |\n",
    "| üìã Research ‡∑É‡∑Ñ experimentation | üí∞ Limited computational resources |\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### 1. K Value ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂±\n",
    "```python\n",
    "# Common choices\n",
    "k_values = [3, 5, 10]\n",
    "\n",
    "# Small datasets: k=5 ‡∑Ñ‡∑ù k=10\n",
    "# Large datasets: k=3 ‡∑Ñ‡∑ù k=5\n",
    "# Very small datasets: Leave-One-Out\n",
    "```\n",
    "\n",
    "### 2. Stratification ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "```python\n",
    "# Classification ‡∑É‡∂≥‡∑Ñ‡∑è\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "```\n",
    "\n",
    "### 3. Random State Set ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n",
    "```python\n",
    "# Reproducible results ‡∑É‡∂≥‡∑Ñ‡∑è\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "```\n",
    "\n",
    "## ‡∑É‡∑è‡∂ª‡∑è‡∂Ç‡∑Å‡∂∫\n",
    "\n",
    "K-Fold Cross Validation ‡∂∫‡∂±‡∑î:\n",
    "- Model performance ‡∂±‡∑í‡∑Ä‡∑ê‡∂ª‡∂Ø‡∑í‡∑Ä ‡∂∏‡∑ê‡∂±‡∑ì‡∂∏‡∑ö ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∂∫‡∂ö‡∑ä\n",
    "- Data ‡∂ë‡∂ö K ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä ‡∑Ä‡∂Ω‡∂ß ‡∂∂‡∑ô‡∂Ø‡∑ì‡∂∏\n",
    "- K ‡∑Ä‡∂≠‡∑è‡∑Ä‡∂ö‡∑ä train/test ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏  \n",
    "- Average performance ‡∂ú‡∂´‡∂±‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏\n",
    "\n",
    "**‡∂∏‡∂≠‡∂ö ‡∂≠‡∂∂‡∑è ‡∂ú‡∂±‡∑ä‡∂±**: \"‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä‡∑É‡∂±‡∑ì‡∂∫ results ‡∑É‡∂≥‡∑Ñ‡∑è, data ‡∂ë‡∂ö ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä ‡∂ö‡∂ª‡∂Ω‡∑è multiple times test ‡∂ö‡∂ª‡∂±‡∑ä‡∂±!\"\n",
    "\n",
    "---\n",
    "\n",
    "**Tips**: \n",
    "- ‡∑É‡∑î‡∑Ö‡∑î datasets ‡∑É‡∂≥‡∑Ñ‡∑è k=10 ‡∑Ä‡∂©‡∑è ‡∑Ñ‡∑ú‡∂≥‡∂∫‡∑í\n",
    "- ‡∑Ä‡∑í‡∑Å‡∑è‡∂Ω datasets ‡∑É‡∂≥‡∑Ñ‡∑è k=5 ‡∂¥‡∑ä‚Äç‡∂ª‡∂∏‡∑è‡∂´‡∑Ä‡∂≠‡∑ä\n",
    "- Class imbalance ‡∂≠‡∑í‡∂∂‡∑ö ‡∂±‡∂∏‡∑ä StratifiedKFold ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (StratifiedKFold,cross_validate)\n",
    "from sklearn.metrics import (confusion_matrix,f1_score,recall_score,precision_score,accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('artifacts/X_train.npz')['arr_0']\n",
    "Y_train = np.load('artifacts/Y_train.npz')['arr_0']\n",
    "X_test = np.load('artifacts/X_test.npz')['arr_0']\n",
    "Y_test = np.load('artifacts/Y_test.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Fold Cross Validation Configuration\n",
    "\n",
    "Setting up StratifiedKFold to maintain class distribution across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(\n",
    "    n_splits=6,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "    model_lr,\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "for s in score_metrics:\n",
    "    cv_results = cross_validate(\n",
    "        model_lr,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        cv=cv,\n",
    "        scoring=s,\n",
    "        return_train_score=False\n",
    "        )\n",
    "    test_score = cv_results['test_score']\n",
    "    test_score_avg = np.mean(test_score)\n",
    "    # print(test_score_avg)\n",
    "\n",
    "    print(f'{s}\\t\\t{test_score_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_f1_fixed = cross_validate(\n",
    "        model_lr,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        return_train_score=False\n",
    "        )\n",
    "        \n",
    "cv_results_f1_fixed_test_score = cv_results_f1_fixed['test_score']\n",
    "best_index = np.argmax(cv_results_f1_fixed_test_score)\n",
    "\n",
    "fold_indices = list(cv.split(X_train,Y_train))\n",
    "\n",
    "best_train_idx, best_test_idx = fold_indices[best_index]\n",
    "\n",
    "X_train_BEST = X_train[best_train_idx]\n",
    "Y_train_BEST = Y_train[best_train_idx]\n",
    "X_test_BEST = X_train[best_train_idx]\n",
    "Y_test_BEST = Y_train[best_train_idx]\n",
    "model_lr = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "model_lr.fit(X_train_BEST,Y_train_BEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = model_lr.predict(X_train)\n",
    "Y_hat_test = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(Y_test, Y_hat_test)\n",
    "precision = precision_score(Y_test, Y_hat_test)\n",
    "recall = recall_score(Y_test, Y_hat_test)\n",
    "f1 = f1_score(Y_test, Y_hat_test)\n",
    "\n",
    "print(\"--- Model Performance Metrics ---\")\n",
    "print(f\"| Metric    | Score   |\")\n",
    "print(f\"|-----------|---------|\")\n",
    "print(f\"| Accuracy  | {accuracy:.4f}  |\")\n",
    "print(f\"| Precision | {precision:.4f}  |\")\n",
    "print(f\"| Recall    | {recall:.4f}  |\")\n",
    "print(f\"| F1-Score  | {f1:.4f}  |\")\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_hat_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not Churned', 'Churned'], \n",
    "            yticklabels=['Not Churned', 'Churned'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.title('Confusion Matrix for Test Set')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
